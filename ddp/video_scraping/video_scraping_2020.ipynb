{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"name":"크롤링_다운로드_1_02.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"code","metadata":{"id":"add3bda1","executionInfo":{"status":"ok","timestamp":1628571380790,"user_tz":-540,"elapsed":302,"user":{"displayName":"양소유","photoUrl":"","userId":"02443691771264125358"}}},"source":["from selenium import webdriver\n","import time\n","from bs4 import BeautifulSoup\n","import requests\n","import urllib.request\n","import webbrowser\n","import os\n","import pandas as pd\n","from datetime import datetime, timedelta\n","import urllib.request\n","\n","chrome_options = webdriver.ChromeOptions()\n","chrome_options.add_argument('--headless')\n","chrome_options.add_argument('--no-sandbox')\n","chrome_options.add_argument('--disable-dev-shm-usage')"],"id":"add3bda1","execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"f350cb2a","scrolled":true},"source":["#전처리 부분\n","\n","#파일 받아오기\n","file = \"/content/drive/MyDrive/dp/full_video_list_2020.csv\"\n","df=pd.read_csv(file)\n","\n","#컬럼명 지정\n","df.columns=['a','team','site']\n","\n","#team컬럼에 [다시보기]제거\n","df['team']=df['team'].str.replace('\\[다시보기\\] ','')\n","\n","#필요없는 컬럼 제거\n","df.drop(['a'],axis=1,inplace=True)\n","\n","#dh(더블헤더)컬럼 생성\n","def read_dh(s):\n","  if 'DH1' in s:\n","    return '1'\n","  elif 'DH2' in s:\n","    return '2'\n","  return '0' \n","\n","df['dh']=df['team'].apply(lambda x:read_dh(x))\n","\n","#team컬럼 형식 통일\n","df['team']=df['team'].str.replace('월_','월 ')\n","df['team']=df['team'].str.replace('일 ','월 ')\n","\n","#team컬럼 '_'기준으로 나눠서 날짜, 파일번호, 팀 컬럼 생성\n","df['date']=df['team'].str.split('_').str[1]\n","df['number']=df['team'].str.split('_').str[2]\n","df['team']=df['team'].str.split('_').str[0]\n","\n","#date컬럼 형식 통일\n","df['date']=df['date'].str.replace(' (DH1)','')\n","\n","#number컬럼 형식 통일\n","df['number']=df['number'].str.replace('부','')\n","\n","#team컬럼 형식을 예) 롯데 vs 삼성 으로 되있는걸 LTSS 이런 형식으로 통일\n","df['team']=df['team'].str.replace(' vs ','')\n","df['team']=df['team'].str.replace('롯데','LT')\n","df['team']=df['team'].str.replace('KIA','HT')\n","df['team']=df['team'].str.replace('키움','WO')\n","df['team']=df['team'].str.replace('두산','OB')\n","df['team']=df['team'].str.replace('SSG','SK')\n","df['team']=df['team'].str.replace('삼성','SS')\n","df['team']=df['team'].str.replace('한화','HH')\n","\n","#team컬럼 필요없는 부분 제거\n","df['team']=df['team'].str[:4]\n","\n","#날짜 형식 통일\n","df['mon']=df['date'].str.split('월 ').str[0]\n","df['day']=df['date'].str.split('월 ').str[1]\n","df['day']=df['day'].str.replace('일','')\n","\n","def change_date(s):\n","    if len(str(s))==1:\n","        return str('0'+s)\n","    else:\n","        return str(s)\n","    \n","df['mon']=df['mon'].apply(lambda x:change_date(x))\n","df['day']=df['day'].apply(lambda x:change_date(x))\n","df['date']='2020'+df['mon']+df['day']\n","df.drop(['mon','day'],axis=1,inplace=True)\n","df"],"id":"f350cb2a","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KBUgynaAbGN8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"KBUgynaAbGN8","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1e1548c9"},"source":["#driver생성\n","driver = webdriver.Chrome(\"c:/data/chromedriver\")#, options=chrome_options)\n","\n","#src가 블롭형식으로 되어있을 때 그 리스트를 받기 위해서 생성\n","blob=pd.DataFrame()\n","\n","#loot dir\n","path='c:/data/'\n","#while문을 돌리기위해 i생성(시작점)\n","i=1000\n","\n","#광고영상이 대신 다운받아지는것을 방지하기 위해 광고일 경우 50초(광고시간)를 기다렸다가 진행\n","t=0\n","\n","#i가 df의 길이 만큼 반복\n","while i < len(df):\n","\n","    #df의 site칼럼에서 url받기\n","    baseUrl = df['site'][i]\n","    #driver실행\n","    driver.get(baseUrl)\n","    soup = BeautifulSoup(driver.page_source, \"html\")\n","    #실행된 site에서 영상 부분 태그\n","    v_url=soup.find('iframe',id='player_vod')['src']\n","    #주소에서 화질 변경 HIGH는 720 HIGH4는 1080\n","    v_url=v_url.replace('HIGH','HIGH4')\n","    #driver실행\n","    driver.get(v_url)\n","    #바로 src를 얻어오면 src가 생성이 되어있지않기 때문에 src가 생성될 수 있게 대기\n","    time.sleep(3)\n","    soup = BeautifulSoup(driver.page_source, \"html\")\n","    \n","    #광고영상 url엔 creative가 들어가기 때문에 creative가 들어있을 경우 다시 반복\n","    if 'creative' in soup.find('video',id='videoElement')['src']:\n","        continue\n","    #src가 blob으로 되어있는 경우 blob df에 넣기 \n","    if 'blob' in soup.find('video',id='videoElement')['src']:\n","        blob=blob.append(df.loc[i])\n","    else:\n","        #print(soup.find('video',id='videoElement')['src'])\n","        start=time.time()\n","        print('start: ',start)\n","        #파일 다운받기 형식은 날짜+팀+dh+년도+영상번호.mp4\n","        urllib.request.urlretrieve(soup.find('video',id='videoElement')['src'],path+df['date'][i]+df['team'][i]+df['dh'][i]+'2021-'+df['number'][i]+'.mp4')\n","        end=time.time()\n","        print('end: ',end)\n","        print(end-start)\n","    i+=1"],"id":"1e1548c9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"atv1lpzV1sxH"},"source":["#시작점 끝점 직접입력\n","\n","#driver생성\n","driver = webdriver.Chrome(\"c:/data/chromedriver\")#, options=chrome_options)\n","\n","#src가 블롭형식으로 되어있을 때 그 리스트를 받기 위해서 생성\n","blob=pd.DataFrame()\n","\n","#loot dir\n","path='c:/data/'\n","\n","#while문을 돌리기위해 i생성(시작점) 직접입력받음\n","i=int(input(\"시작점\"))\n","\n","last=int(input(\"끝점\"))\n","#광고영상이 대신 다운받아지는것을 방지하기 위해 광고일 경우 50초(광고시간)를 기다렸다가 진행\n","t=0\n","\n","#i가 df의 길이 만큼 반복\n","while i < last+1:\n","    print(i)\n","    #df의 site칼럼에서 url받기\n","    baseUrl = df['site'][i]\n","    #driver실행\n","    driver.get(baseUrl)\n","    soup = BeautifulSoup(driver.page_source, \"html\")\n","    #실행된 site에서 영상 부분 태그\n","    v_url=soup.find('iframe',id='player_vod')['src']\n","    #주소에서 화질 변경 HIGH는 720 HIGH4는 1080\n","    v_url=v_url.replace('HIGH','HIGH4')\n","    #driver실행\n","    driver.get(v_url)\n","    #바로 src를 얻어오면 src가 생성이 되어있지않기 때문에 src가 생성될 수 있게 대기\n","    time.sleep(3)\n","    soup = BeautifulSoup(driver.page_source, \"html\")  \n","    #광고영상 url엔 creative가 들어가기 때문에 creative가 들어있을 경우 다시 반복\n","    if 'creative' in soup.find('video',id='videoElement')['src']:\n","        continue\n","    #src가 blob으로 되어있는 경우 blob df에 넣기 \n","    if 'blob' in soup.find('video',id='videoElement')['src']:\n","        blob=blob.append(df.loc[i])\n","    else:\n","        #print(soup.find('video',id='videoElement')['src'])\n","        start=time.time()\n","        print('start: ',start)\n","        #파일 다운받기 형식은 날짜+팀+dh+년도+영상번호.mp4\n","        urllib.request.urlretrieve(soup.find('video',id='videoElement')['src'],path+df['date'][i]+df['team'][i]+df['dh'][i]+'2021-'+df['number'][i]+'.mp4')\n","        end=time.time()\n","        print('end: ',end)\n","        print(end-start)\n","    i+=1"],"id":"atv1lpzV1sxH","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_PlV8IzLKNZ"},"source":["#다운이 실행된 영상 중 오류로 안받아 졌거나 광고가 다운 받아져 있는 경우\n","#while문을 돌리기위해 i생성(시작점) 직접입력받음\n","i=int(input(\"시작점\"))\n","\n","last=int(input(\"끝점\"))\n","\n","#loot dir\n","path='c:/data/'\n","\n","#loot dir에 있는 파일 리스트\n","dir_list=os.listdir(path)\n","\n","driver = webdriver.Chrome(\"c:/data/chromedriver\")\n","\n","#src가 블롭형식으로 되어있을 때 그 리스트를 받기 위해서 생성\n","blob=pd.DataFrame()\n","\n","check_down=False\n","while i < last+1:\n","    #파일이 다운받아져있는지 확인\n","    if os.path.basename(df['date'][i]+df['team'][i]+df['dh'][i]+'2021-'+df['number'][i]+'.mp4') in dir_list:\n","        #받아져 있더라도 광고라면 다시 받기\n","        if os.path.getsize(path+df['date'][i]+df['team'][i]+df['dh'][i]+'2021-'+df['number'][i]+'.mp4')<6000000:\n","            #다시 다운 받을 건지 확인하는 변수 true면 다시 다운\n","            check_down=True    \n","    #파일이 없으면 다운 받기\n","    else:\n","        check_down=True\n","    #check_down이 True면\n","    if check_down:\n","        print(i)\n","        #df의 site칼럼에서 url받기\n","        baseUrl = df['site'][i]\n","        #driver실행\n","        driver.get(baseUrl)\n","        soup = BeautifulSoup(driver.page_source, \"html\")\n","        #실행된 site에서 영상 부분 태그\n","        v_url=soup.find('iframe',id='player_vod')['src']\n","        #주소에서 화질 변경 HIGH는 720 HIGH4는 1080\n","        v_url=v_url.replace('HIGH','HIGH4')\n","        #driver실행\n","        driver.get(v_url)\n","        #바로 src를 얻어오면 src가 생성이 되어있지않기 때문에 src가 생성될 수 있게 대기\n","        time.sleep(3)\n","        soup = BeautifulSoup(driver.page_source, \"html\")  \n","        #광고영상 url엔 creative가 들어가기 때문에 creative가 들어있을 경우 다시 반복\n","        if 'creative' in soup.find('video',id='videoElement')['src']:\n","            check_down=False\n","            continue\n","        #src가 blob으로 되어있는 경우 blob df에 넣기 \n","        if 'blob' in soup.find('video',id='videoElement')['src']:\n","            blob=blob.append(df.loc[i])\n","        else:\n","            #print(soup.find('video',id='videoElement')['src'])\n","            start=time.time()\n","            print('start: ',start)\n","            #파일 다운받기 형식은 날짜+팀+dh+년도+영상번호.mp4\n","            urllib.request.urlretrieve(soup.find('video',id='videoElement')['src'],path+df['date'][i]+df['team'][i]+df['dh'][i]+'2021-'+df['number'][i]+'.mp4')\n","            end=time.time()\n","            print('end: ',end)\n","            print(end-start)\n","    check_down=False\n","    i+=1"],"id":"V_PlV8IzLKNZ","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d0388bf5"},"source":[""],"id":"d0388bf5","execution_count":null,"outputs":[]}]}